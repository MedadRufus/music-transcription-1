{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp06x85pvh/m91973e5c136ea49268a916ff971b7377.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp06x85pvh/m91973e5c136ea49268a916ff971b7377.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from onset_detection.read_data import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for AR_Lick11_FN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for AR_Lick11_KN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for AR_Lick11_MN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:152: UserWarning: Skipping non-wav file data\\IDMT-SMT-GUITAR_V2\\dataset2\\audio\\desktop.ini\n",
      "  warn('Skipping non-wav file ' + path_to_wav)\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for FS_Lick11_FN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for FS_Lick11_KN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for FS_Lick11_MN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for LP_Lick11_FN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for LP_Lick11_KN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:150: UserWarning: No truth found for LP_Lick11_MN.wav, skipping file.\n",
      "  warn('No truth found for ' + wav_file + ', skipping file.')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Career SG\\fast\\country_folk\\audio\\country_1_150BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Career SG\\fast\\metal\\audio\\metal_3_135BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Career SG\\fast\\rock_blues\\audio\\rock_1_120BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Career SG\\fast\\rock_blues\\audio\\rock_2_115BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\classical\\audio\\classical_8_100BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_1_160BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_2_170BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_3_120BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_4_70BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_5_80BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_6_150BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_7_140BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\jazz\\audio\\jazz_8_110BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\reggae_ska\\audio\\reggae_2_100BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:171: UserWarning: Skipping data\\IDMT-SMT-GUITAR_V2\\dataset4\\Ibanez 2820\\slow\\rock_blues\\audio\\rock_5_100BPM.wav: no truth csv\n",
      "  warn('Skipping ' + path_to_wav + ': no truth csv')\n",
      "D:\\Users\\Michel\\Documents\\FH\\module\\8_IP6\\git\\onset_detection\\read_data.py:14: UserWarning: Cannot handle stereo signal (data\\IDMT-SMT-GUITAR_V2\\dataset3\\audio\\pathetique_poly.wav), skipping file.\n",
      "  warn('Cannot handle stereo signal (' + path_to_wav + '), skipping file.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171926, 111)\n",
      "(1171926,)\n",
      "51536\n"
     ]
    }
   ],
   "source": [
    "active_datasets = {'ds1', 'ds2', 'ds3', 'ds4'}\n",
    "X, y = read_data(active_datasets)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937540, 111)\n",
      "(937540,)\n",
      "(234386, 111)\n",
      "(234386,)\n",
      "1.60520331603e-19\n",
      "1.0\n",
      "-9.37002541738e-05\n",
      "1.00155776089\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "print(X_train.mean())\n",
    "print(X_train.std())\n",
    "print(X_test.mean())\n",
    "print(X_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937540, 111, 1)\n",
      "(234386, 111, 1)\n",
      "(111, 1)\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "X_train = X_train.reshape(X_train.shape[0], input_dim, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], input_dim, 1)\n",
    "input_shape = (input_dim, 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 937540 samples, validate on 234386 samples\n",
      "Epoch 1/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1559 - val_loss: 0.1344\n",
      "Epoch 2/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1276 - val_loss: 0.1240\n",
      "Epoch 3/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1205 - val_loss: 0.1198\n",
      "Epoch 4/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1168 - val_loss: 0.1166\n",
      "Epoch 5/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1148 - val_loss: 0.1156\n",
      "Epoch 6/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1127 - val_loss: 0.1157\n",
      "Epoch 7/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1113 - val_loss: 0.1141\n",
      "Epoch 8/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1099 - val_loss: 0.1132\n",
      "Epoch 9/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1085 - val_loss: 0.1131\n",
      "Epoch 10/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1075 - val_loss: 0.1126\n",
      "Epoch 11/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1065 - val_loss: 0.1123\n",
      "Epoch 12/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1053 - val_loss: 0.1139\n",
      "Epoch 13/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1045 - val_loss: 0.1115\n",
      "Epoch 14/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1035 - val_loss: 0.1114\n",
      "Epoch 15/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1028 - val_loss: 0.1118\n",
      "Epoch 16/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1017 - val_loss: 0.1117\n",
      "Epoch 17/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1010 - val_loss: 0.1109\n",
      "Epoch 18/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.1000 - val_loss: 0.1107\n",
      "Epoch 19/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0995 - val_loss: 0.1115\n",
      "Epoch 20/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0986 - val_loss: 0.1113\n",
      "Epoch 21/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0977 - val_loss: 0.1125\n",
      "Epoch 22/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0972 - val_loss: 0.1123\n",
      "Epoch 23/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0964 - val_loss: 0.1131\n",
      "Epoch 24/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0958 - val_loss: 0.1129\n",
      "Epoch 25/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0951 - val_loss: 0.1133\n",
      "Epoch 26/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0945 - val_loss: 0.1130\n",
      "Epoch 27/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0938 - val_loss: 0.1114\n",
      "Epoch 28/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0931 - val_loss: 0.1131\n",
      "Epoch 29/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0926 - val_loss: 0.1132\n",
      "Epoch 30/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0921 - val_loss: 0.1128\n",
      "Epoch 31/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0914 - val_loss: 0.1132\n",
      "Epoch 32/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0910 - val_loss: 0.1147\n",
      "Epoch 33/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0901 - val_loss: 0.1151\n",
      "Epoch 34/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0897 - val_loss: 0.1149\n",
      "Epoch 35/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0891 - val_loss: 0.1156\n",
      "Epoch 36/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0886 - val_loss: 0.1160\n",
      "Epoch 37/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0876 - val_loss: 0.1160\n",
      "Epoch 38/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0871 - val_loss: 0.1156\n",
      "Epoch 39/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0865 - val_loss: 0.1167\n",
      "Epoch 40/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0859 - val_loss: 0.1198\n",
      "Epoch 41/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0853 - val_loss: 0.1166\n",
      "Epoch 42/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0847 - val_loss: 0.1183\n",
      "Epoch 43/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0841 - val_loss: 0.1181\n",
      "Epoch 44/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0836 - val_loss: 0.1193\n",
      "Epoch 45/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0830 - val_loss: 0.1203\n",
      "Epoch 46/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0825 - val_loss: 0.1199\n",
      "Epoch 47/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0817 - val_loss: 0.1226\n",
      "Epoch 48/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0812 - val_loss: 0.1206\n",
      "Epoch 49/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0807 - val_loss: 0.1220\n",
      "Epoch 50/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.0802 - val_loss: 0.1219\n",
      "Epoch 51/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0797 - val_loss: 0.1221\n",
      "Epoch 52/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.0791 - val_loss: 0.1252\n",
      "Epoch 53/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0785 - val_loss: 0.1247\n",
      "Epoch 54/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0782 - val_loss: 0.1243\n",
      "Epoch 55/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0774 - val_loss: 0.1261\n",
      "Epoch 56/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0772 - val_loss: 0.1271\n",
      "Epoch 57/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0766 - val_loss: 0.1268\n",
      "Epoch 58/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.0759 - val_loss: 0.1292\n",
      "Epoch 59/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.0755 - val_loss: 0.1287\n",
      "Epoch 60/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0751 - val_loss: 0.1302\n",
      "Epoch 61/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0745 - val_loss: 0.1301\n",
      "Epoch 62/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0740 - val_loss: 0.1316\n",
      "Epoch 63/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0735 - val_loss: 0.1315\n",
      "Epoch 64/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0730 - val_loss: 0.1331\n",
      "Epoch 65/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0727 - val_loss: 0.1354\n",
      "Epoch 66/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0721 - val_loss: 0.1352\n",
      "Epoch 67/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0716 - val_loss: 0.1353\n",
      "Epoch 68/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0712 - val_loss: 0.1369\n",
      "Epoch 69/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0708 - val_loss: 0.1374\n",
      "Epoch 70/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0702 - val_loss: 0.1397\n",
      "Epoch 71/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0694 - val_loss: 0.1400\n",
      "Epoch 72/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0695 - val_loss: 0.1390\n",
      "Epoch 73/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0689 - val_loss: 0.1394\n",
      "Epoch 74/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0684 - val_loss: 0.1421\n",
      "Epoch 75/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0681 - val_loss: 0.1427\n",
      "Epoch 76/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0675 - val_loss: 0.1417\n",
      "Epoch 77/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0669 - val_loss: 0.1433\n",
      "Epoch 78/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0664 - val_loss: 0.1466\n",
      "Epoch 79/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0662 - val_loss: 0.1460\n",
      "Epoch 80/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0656 - val_loss: 0.1461\n",
      "Epoch 81/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0652 - val_loss: 0.1483\n",
      "Epoch 82/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0649 - val_loss: 0.1490\n",
      "Epoch 83/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0643 - val_loss: 0.1513\n",
      "Epoch 84/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0640 - val_loss: 0.1529\n",
      "Epoch 85/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0637 - val_loss: 0.1519\n",
      "Epoch 86/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0631 - val_loss: 0.1561\n",
      "Epoch 87/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0628 - val_loss: 0.1547\n",
      "Epoch 88/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0626 - val_loss: 0.1545\n",
      "Epoch 89/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0622 - val_loss: 0.1548\n",
      "Epoch 90/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0616 - val_loss: 0.1567\n",
      "Epoch 91/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0610 - val_loss: 0.1585\n",
      "Epoch 92/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0611 - val_loss: 0.1582\n",
      "Epoch 93/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0603 - val_loss: 0.1599\n",
      "Epoch 94/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0604 - val_loss: 0.1619\n",
      "Epoch 95/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0599 - val_loss: 0.1638\n",
      "Epoch 96/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0591 - val_loss: 0.1666\n",
      "Epoch 97/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0593 - val_loss: 0.1663\n",
      "Epoch 98/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.0585 - val_loss: 0.1663\n",
      "Epoch 99/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0581 - val_loss: 0.1661\n",
      "Epoch 100/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0578 - val_loss: 0.1665\n",
      "Epoch 101/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0579 - val_loss: 0.1666\n",
      "Epoch 102/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0574 - val_loss: 0.1702\n",
      "Epoch 103/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0570 - val_loss: 0.1726\n",
      "Epoch 104/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0564 - val_loss: 0.1712\n",
      "Epoch 105/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0561 - val_loss: 0.1693\n",
      "Epoch 106/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0559 - val_loss: 0.1758\n",
      "Epoch 107/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0555 - val_loss: 0.1747\n",
      "Epoch 108/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0553 - val_loss: 0.1770\n",
      "Epoch 109/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0546 - val_loss: 0.1764\n",
      "Epoch 110/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0545 - val_loss: 0.1814\n",
      "Epoch 111/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0541 - val_loss: 0.1788\n",
      "Epoch 112/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0541 - val_loss: 0.1836\n",
      "Epoch 113/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0536 - val_loss: 0.1822\n",
      "Epoch 114/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0532 - val_loss: 0.1835\n",
      "Epoch 115/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0532 - val_loss: 0.1859\n",
      "Epoch 116/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0524 - val_loss: 0.1842\n",
      "Epoch 117/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0523 - val_loss: 0.1846\n",
      "Epoch 118/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0522 - val_loss: 0.1897\n",
      "Epoch 119/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0516 - val_loss: 0.1874\n",
      "Epoch 120/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0516 - val_loss: 0.1879\n",
      "Epoch 121/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0510 - val_loss: 0.1896\n",
      "Epoch 122/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0509 - val_loss: 0.1886\n",
      "Epoch 123/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0502 - val_loss: 0.1944\n",
      "Epoch 124/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0503 - val_loss: 0.1935\n",
      "Epoch 125/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0499 - val_loss: 0.1929\n",
      "Epoch 126/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0502 - val_loss: 0.1954\n",
      "Epoch 127/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0493 - val_loss: 0.1972\n",
      "Epoch 128/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0490 - val_loss: 0.1957\n",
      "Epoch 129/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0488 - val_loss: 0.2014\n",
      "Epoch 130/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0489 - val_loss: 0.1988\n",
      "Epoch 131/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0482 - val_loss: 0.2024\n",
      "Epoch 132/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0479 - val_loss: 0.2060\n",
      "Epoch 133/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0480 - val_loss: 0.2031\n",
      "Epoch 134/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0473 - val_loss: 0.2067\n",
      "Epoch 135/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0474 - val_loss: 0.2038\n",
      "Epoch 136/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0473 - val_loss: 0.2029\n",
      "Epoch 137/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0469 - val_loss: 0.2056\n",
      "Epoch 138/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0465 - val_loss: 0.2094\n",
      "Epoch 139/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0460 - val_loss: 0.2073\n",
      "Epoch 140/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0466 - val_loss: 0.2133\n",
      "Epoch 141/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0453 - val_loss: 0.2162\n",
      "Epoch 142/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0455 - val_loss: 0.2124\n",
      "Epoch 143/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0455 - val_loss: 0.2158\n",
      "Epoch 144/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0451 - val_loss: 0.2135\n",
      "Epoch 145/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0448 - val_loss: 0.2162\n",
      "Epoch 146/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0450 - val_loss: 0.2169\n",
      "Epoch 147/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0443 - val_loss: 0.2148\n",
      "Epoch 148/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0440 - val_loss: 0.2181\n",
      "Epoch 149/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0441 - val_loss: 0.2207\n",
      "Epoch 150/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0433 - val_loss: 0.2231\n",
      "Epoch 151/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0435 - val_loss: 0.2195\n",
      "Epoch 152/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0436 - val_loss: 0.2243\n",
      "Epoch 153/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0427 - val_loss: 0.2264\n",
      "Epoch 154/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0426 - val_loss: 0.2271\n",
      "Epoch 155/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0424 - val_loss: 0.2274\n",
      "Epoch 156/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0424 - val_loss: 0.2289\n",
      "Epoch 157/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0422 - val_loss: 0.2290\n",
      "Epoch 158/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0417 - val_loss: 0.2288\n",
      "Epoch 159/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0417 - val_loss: 0.2328\n",
      "Epoch 160/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0417 - val_loss: 0.2332\n",
      "Epoch 161/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0411 - val_loss: 0.2305\n",
      "Epoch 162/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0412 - val_loss: 0.2355\n",
      "Epoch 163/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0407 - val_loss: 0.2355\n",
      "Epoch 164/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0406 - val_loss: 0.2368\n",
      "Epoch 165/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0402 - val_loss: 0.2344\n",
      "Epoch 166/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0406 - val_loss: 0.2382\n",
      "Epoch 167/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0399 - val_loss: 0.2409\n",
      "Epoch 168/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0401 - val_loss: 0.2416\n",
      "Epoch 169/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0399 - val_loss: 0.2390\n",
      "Epoch 170/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0394 - val_loss: 0.2459\n",
      "Epoch 171/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0394 - val_loss: 0.2426\n",
      "Epoch 172/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0392 - val_loss: 0.2445\n",
      "Epoch 173/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0387 - val_loss: 0.2450\n",
      "Epoch 174/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0381 - val_loss: 0.2469\n",
      "Epoch 175/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0388 - val_loss: 0.2502\n",
      "Epoch 176/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0382 - val_loss: 0.2495\n",
      "Epoch 177/500\n",
      "937540/937540 [==============================] - 16s - loss: 0.0384 - val_loss: 0.2498\n",
      "231424/234386 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape=(111, 1), dropout=False):\n",
    "    nb_filter = 32\n",
    "    filter_length = 8\n",
    "    border_mode = 'same'\n",
    "    pool_length = 2\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter, filter_length,\n",
    "                            border_mode=border_mode,\n",
    "                            input_shape=input_shape,))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_length=pool_length))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',)\n",
    "    \n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(\n",
    "    build_fn=create_model,\n",
    "    batch_size=1024, nb_epoch=500,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[EarlyStopping(monitor='loss', patience=2)],\n",
    "    input_shape=input_shape,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predicted = clf.predict(X_train)\n",
    "y_test_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99    896320\n",
      "          1       0.91      0.82      0.86     41220\n",
      "\n",
      "avg / total       0.99      0.99      0.99    937540\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98    224070\n",
      "          1       0.50      0.44      0.47     10316\n",
      "\n",
      "avg / total       0.95      0.96      0.95    234386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_predicted))\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpfpg9l6rs/md953f6e2da014848347663cc100f1fd6.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpfpg9l6rs/md953f6e2da014848347663cc100f1fd6.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp8ty16h_5/mc8064d39203a98af4ed4d35a8d09bf0b.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmp8ty16h_5/mc8064d39203a98af4ed4d35a8d09bf0b.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpjt5su9yh/m497f9daba605b74502a9d0dcc5280d00.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpjt5su9yh/m497f9daba605b74502a9d0dcc5280d00.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpy0u8dkyw/mb91a1b1d636a14689fa9731b6e3a8a55.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpy0u8dkyw/mb91a1b1d636a14689fa9731b6e3a8a55.exp\n",
      "\n",
      "DEBUG: nvcc STDOUT mod.cu\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpeb24px12/mf754e6a2b256c0fce593ae471ced61fe.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmpeb24px12/mf754e6a2b256c0fce593ae471ced61fe.exp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 937540 samples, validate on 234386 samples\n",
      "Epoch 1/500\n",
      "  4096/937540 [..............................] - ETA: 20s - loss: 0.5765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: nvcc STDOUT mod.cu\r\n",
      "   Creating library D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmppnfmri5n/mda0425657fec5f52bc6b79603f6788cd.lib and object D:/Temp/theano_compiledir/compiledir_Windows-10-10.0.14393-SP0-Intel64_Family_6_Model_60_Stepping_3_GenuineIntel-3.5.2-64/tmppnfmri5n/mda0425657fec5f52bc6b79603f6788cd.exp\r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937540/937540 [==============================] - 17s - loss: 0.1666 - val_loss: 0.1409\n",
      "Epoch 2/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1430 - val_loss: 0.1312\n",
      "Epoch 3/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1356 - val_loss: 0.1266\n",
      "Epoch 4/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1315 - val_loss: 0.1242\n",
      "Epoch 5/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1288 - val_loss: 0.1220\n",
      "Epoch 6/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1265 - val_loss: 0.1214\n",
      "Epoch 7/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1249 - val_loss: 0.1193\n",
      "Epoch 8/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1234 - val_loss: 0.1188\n",
      "Epoch 9/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1222 - val_loss: 0.1172\n",
      "Epoch 10/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1212 - val_loss: 0.1168\n",
      "Epoch 11/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1204 - val_loss: 0.1169\n",
      "Epoch 12/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1196 - val_loss: 0.1165\n",
      "Epoch 13/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1187 - val_loss: 0.1161\n",
      "Epoch 14/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1181 - val_loss: 0.1148\n",
      "Epoch 15/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1180 - val_loss: 0.1152\n",
      "Epoch 16/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1174 - val_loss: 0.1140\n",
      "Epoch 17/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1169 - val_loss: 0.1156\n",
      "Epoch 18/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1166 - val_loss: 0.1135\n",
      "Epoch 19/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1165 - val_loss: 0.1138\n",
      "Epoch 20/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1159 - val_loss: 0.1138\n",
      "Epoch 21/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1154 - val_loss: 0.1130\n",
      "Epoch 22/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1155 - val_loss: 0.1142\n",
      "Epoch 23/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1151 - val_loss: 0.1123\n",
      "Epoch 24/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1148 - val_loss: 0.1125\n",
      "Epoch 25/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1144 - val_loss: 0.1117\n",
      "Epoch 26/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1145 - val_loss: 0.1120\n",
      "Epoch 27/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1143 - val_loss: 0.1113\n",
      "Epoch 28/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1142 - val_loss: 0.1115\n",
      "Epoch 29/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1139 - val_loss: 0.1124\n",
      "Epoch 30/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1136 - val_loss: 0.1141\n",
      "Epoch 31/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1134 - val_loss: 0.1111\n",
      "Epoch 32/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1129 - val_loss: 0.1112\n",
      "Epoch 33/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1131 - val_loss: 0.1103\n",
      "Epoch 34/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1129 - val_loss: 0.1114\n",
      "Epoch 35/500\n",
      "937540/937540 [==============================] - 17s - loss: 0.1130 - val_loss: 0.1109\n",
      "230400/234386 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "clf = KerasClassifier(\n",
    "    build_fn=create_model,\n",
    "    batch_size=1024, nb_epoch=500,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[EarlyStopping(monitor='loss', patience=2)],\n",
    "    input_shape=input_shape, dropout=True,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_predicted = clf.predict(X_train)\n",
    "y_test_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98    896320\n",
      "          1       0.86      0.29      0.44     41220\n",
      "\n",
      "avg / total       0.96      0.97      0.96    937540\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98    224070\n",
      "          1       0.82      0.27      0.41     10316\n",
      "\n",
      "avg / total       0.96      0.97      0.96    234386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_predicted))\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
